{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement \n",
    "\n",
    "The problem statement is to detect intrusions from a tcp dump.The data is provided in csv files so no feature extraction is involved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import fetch_data \n",
    "from data import feature_engineering\n",
    "from models.model import Model\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from Para_learn import paralearn\n",
    "import pickle\n",
    "from flask import request\n",
    "from cross_val import k_fold_crossval\n",
    "%matplotlib inline \n",
    "root=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded :)\n",
      "The dimensions of the training dataset is (145583, 41)\n",
      "The dimensions of test dataset is (311028, 41)\n",
      "The taken to load data is 4.65 secs\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = fetch_data(root,remove_duplicates=True,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data after feature engineering is (145583, 45)\n",
      "Shape of test data after feature engineering is (311028, 45)\n"
     ]
    }
   ],
   "source": [
    "x_train = feature_engineering(x_train,do_normalization=False)\n",
    "x_test = feature_engineering(x_test,do_normalization=False)\n",
    "print('Shape of training data after feature engineering is {}'.format(x_train.shape))\n",
    "print ('Shape of test data after feature engineering is {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf=Model(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77644 10170]\n",
      " [18535 39234]]\n",
      "The f1 score for NAIVE BAYES model on training data is 0.7321620184188181\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES\n",
    "nb=clf.mnbayes(x_train,y_train)\n",
    "predict_train_nb=nb.predict(x_train)\n",
    "conf_matrix_nb=confusion_matrix(list(y_train),(predict_train_nb).round())\n",
    "f1_score_train_nb=f1_score(list(y_train),(predict_train_nb).round())\n",
    "print (conf_matrix_nb)\n",
    "print('The f1 score for NAIVE BAYES model on training data is {}'.format(f1_score_train_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for 1 iteration................. 0.6481\n",
      "f1 score for 2 iteration................. 0.6467\n",
      "f1 score for 3 iteration................. 0.6550\n",
      "f1 score for 4 iteration................. 0.6318\n",
      "f1 score for 5 iteration................. 0.8785\n",
      "f1 score for 6 iteration................. 0.6561\n"
     ]
    }
   ],
   "source": [
    "cross_val_score_nb=k_fold_crossval(nb,x_train,y_train,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "svm=clf.svm(x_train,y_train)\n",
    "predict_train_svm=svm.predict(x_train)\n",
    "conf_matrix_svm=confusion_matrix(list(y_train),(predict_train_svm).round())\n",
    "f1_score_train_svm=f1_score(list(y_train),(predict_train_svm).round())\n",
    "print (conf_matrix_svm)\n",
    "print('The f1 score for SUPPORT VECTOR MACHINES model on training data is {}'.format(f1_score_train_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score_svm=k_fold_crossval(svm,x_train,y_train,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST \n",
    "xgb,x_dtrain,x_dtest=clf.xgboost(x_train,y_train,x_test)\n",
    "predict_train_xgb=xgb.predict(x_dtrain)\n",
    "conf_matrix_xgb=confusion_matrix(list(y_train),(predict_train_xgb).round())\n",
    "f1_score_train_xgb=f1_score(list(y_train),(predict_train_xgb).round())\n",
    "print (conf_matrix_xgb)\n",
    "print('The f1 score for XGBOOST model on training data is {}'.format(f1_score_train_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking whether this is a overfit on the training data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87814     0]\n",
      " [   17 57752]]\n",
      "The f1 score for RANDOM FOREST model on training data is 0.9999\n"
     ]
    }
   ],
   "source": [
    "#RANDOMFOREST \n",
    "rf=clf.randforest(x_train,y_train)\n",
    "predict_train_rf=rf.predict(x_train)\n",
    "conf_matrix_rf=confusion_matrix(list(y_train),(predict_train_rf).round())\n",
    "f1_score_train_rf=f1_score(list(y_train),(predict_train_rf).round())\n",
    "print (conf_matrix_rf)\n",
    "print('The f1 score for RANDOM FOREST model on training data is {:.4f}'.format(f1_score_train_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for 1 iteration................. 0.9993\n",
      "f1 score for 2 iteration................. 0.9992\n",
      "f1 score for 3 iteration................. 0.9990\n",
      "f1 score for 4 iteration................. 0.9988\n",
      "f1 score for 5 iteration................. 0.9993\n",
      "f1 score for 6 iteration................. 0.9989\n"
     ]
    }
   ],
   "source": [
    "# Cross validation to check whether the model is overfitting or not \n",
    "cross_val_score_rf=k_fold_crossval(rf,x_train,y_train,6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection \n",
    "\n",
    "\n",
    "After doing hyperparameter optimization for different models on the training data and computing a metric evaluating the generalization of a particular model,we can select which model will be our best bet for generalizing over to the unseen data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hitting the API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest is the one. Lets save this model somewhere and hit the api to see what happens \n",
    "joblib.dump(rf,'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anurag/Desktop/DS_Training'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hitting the api \n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=2, oob_score=False,\n",
       "            random_state=12345, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open('rf_test.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf,open('rf_test.pkl','wb'),protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
