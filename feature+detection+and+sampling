
# coding: utf-8

#Importing Libraries-------------------------------------------------------------

import numpy as np
import pandas as pd1
import pandas_ml as pd2
from sklearn.ensemble import ExtraTreesClassifier
from collections import Counter
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import ClusterCentroids

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline


#Important Feature detection-------------------------------------------------------

data1 = pd1.read_csv("/home/tatras/Downloads/train_data_with_dummies.csv")
data = pd1.DataFrame(data1)
model=ExtraTreesClassifier(n_estimators=500)
X_train=data.drop('label',axis=1)
Y_train=data['label']
model.fit(X_train,Y_train)
print(model.feature_importances_)
imp=[]
for i,j in zip(list(data)[:-1],model.feature_importances_):
    a=[i,j]
    imp.append(a)
def get_key(item):
    return item[1]
sorted_list=sorted(imp,key=get_key)

features=[]
importance=[]
for i,j in zip(list(data)[:-1],model.feature_importances_):
    features.append(i)
    importance.append(j)

m=features
n=importance

fig, axes = plt.subplots(figsize=(20,10))        
sns.barplot(x=n,y=m,ax=axes)


features=[]
importance=[]
for i,j in zip(list(data)[:-1],model.feature_importances_):
    features.append(i)
    importance.append(j)

m=features
n=importance

fig, axes = plt.subplots(figsize=(20,10))        
sns.barplot(x=n,y=m,ax=axes)


feat_list=[]
imp_list=[]
for i in sorted_list:
    feat_list.append(i[0])
    imp_list.append(i[1])

fig, axes = plt.subplots(figsize=(20,13))        
sns.barplot(y=feat_list,x=imp_list,ax=axes)

imp = model.feature_importances_
imp = model.feature_importances_
thres = 0.1*imp.max()
important_idx = np.where(imp > thres)[0]

important_features = data[important_idx]
important_features

#sample_data = pd1.concat([important_features,Y_train],axis=1)


#Random Oversampling-----------------------------------------


ros = RandomOverSampler(random_state=42,ratio=1.0)
X_res, y_res = ros.fit_sample(important_features, Y_train)
print('Resampled dataset shape {}'.format(Counter(y_res)))
training_data1 = pd1.concat([x_res,y_res],axis=1)


#SMOTE oversampling-------------------------------------------------


sm = SMOTE(random_state=42,ratio=1.0)
x_res,y_res = sm.fit_sample(important_features, Y_train)
print('Resampled dataset shape {}'.format(Counter(y_res)))
training_data2 = pd1.concat([x_res,y_res],axis=1)


#Undersampling by ClusterCentroid method------------------------------------------------------


cc = ClusterCentroids(random_state=42,ratio=1.0)
X_res, y_res = cc.fit_sample(important_features, Y_train)
print('Resampled dataset shape {}'.format(Counter(y_res)))
training_data3 = pd1.concat([x_res,y_res],axis=1)

































